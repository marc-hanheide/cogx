


%%  and
%% using various techniques to manage the large state
%% space

%% \citeauthor{hippo-jnl}~(\citeyear{hippo-jnl}) take this
%% approach in a 



Addressing task and observation planning specifically, there have been
a number of recent developments where the underlying problem is
modelled as a POMDP.
%%
For vision algorithm
selection,~\citeauthor{hippo-jnl}~(\citeyear{hippo-jnl}) exploit a
natural hierarchical decomposition of the underlying POMDP into
subproblems where decision-theoretic planning is reasonably
fast. \citeauthor{doshi08:pref_elic}~(\citeyear{doshi08:pref_elic})
represent a preference elicitation problem as a POMDP and take
advantage of symmetry in the belief space ---essentially the idea that
it does not matter what the value of the variable you are trying to
observe is--- to exponentially shrink the state space. Although we
have been actively exploring the \citeauthor{doshi08:pref_elic}
approach, those exploitable structures are not present in problems we
have considered so far due to the task planning requirement. 
%%
\citeauthor{kurniawati:etal:2010}~(\citeyear{kurniawati:etal:2010}) 
%%
Finally,
our approach is in a similar vein to the more classical {\em
dual-mode} control~\cite{cassandra96actingunder}, however in our case
entropy reduction is targeted by planning in an abstract process which
is informed by one execution trace ---computed by a {\em classical}
planner--- and the underlying belief-state.


More generally, there has been much recent work on scaling POMDP
solution procedures to medium-sized instances~\cite{shani:etal:08}. In
the case of general domain-independent factored systems, the
state-of-the-art scales to relatively small problems with $2^{22}$
states~\cite{shani:etal:2008}. At their limit, these procedures take
over an hour to converge, and $\sim10$ seconds on average to perform a
single Bellman backup.  For classes of POMDP that feature exploitable
structures (e.g., no actions with negative effects), problems with as
many as $10^{30}$ states can be targeted by offline
procedures~\cite{brunskill:russell:2010}. Moving someway towards
addressing real-time decision making, recent online POMDP solution
procedures have been developed which can exploit highly approximate
value functions -- typically computed using a point-based procedure --
and heuristics in forward search~\cite{ross:etal:2008}. Their
applicability in our setting is limited, firstly because they only
scale to smaller problems, with thousands of states, and also due to
the large amount of
\emph{problem-specific} offline processing that might be required to get useful
search guidance. A {\em very} recent and promising online approach for
large POMDPs employs Monte-Carlo sampling to break the curse of
dimensionality in situations where goal reachability is {\em easily}
determined~\cite{silver:veness:2010}.


%% Although we suppose it an interesting
%% item for future work to pursue that direction, it should be noted that
%% ease of goal reachability is not guaranteed in the problems we face,
%% and is certainly not a property to be assumed in domain independent
%% planning.


In the direction of leveraging {\em classical} systems/approaches for
planning under uncertainty, the most highlighted system to date has
been \system{FFR$_a$}~\cite{yoon:etal:2007}; The winning entry from
the probabilistic track of the 2004 International Planning
Competition.  In the continual paradigm, \system{FFR$_a$} uses the
fast satisficing procedure \system{FF}~\cite{hoffmann:nebel:2001} to
compute sequential plans and corresponding execution traces.
%%
More computationally expensive approaches in this vein combine
sampling strategies on valuations over {\em runtime variables} with
deterministic planning procedures. The outcome is typically a more
robust sequential plan~\cite{yoon:etal:2008}, or contingent
plan~\cite{majercik:2006}. 

Also leveraging deterministic planners in problems that feature
uncertainty, \system{Conformant-FF}~\cite{hoffmann:brafman:2006} and
$T_0$~\cite{palacios:geffner:2009} demonstrate how conformant planning
---i.e., sequential planning in unobservable worlds--- can be modelled
as a deterministic problem, and therefore solved using sequential
systems. In this conformant setting, advances have been towards
compact representations of beliefs amenable to existing best-first
search planning procedures, and lazy evaluations of beliefs. Most
recently this research thread has been extended to contingent planning
in fully observable non-deterministic
environments~\cite{albore:etal:2009}.
%%
The continual planning system that motivated our
project~\cite{brenner:nebel:jaamas09} also has this characteristic,
and has been applied in completely observable domains, particularly
those featuring multiple communicating agents. 

%% The use of knowledge
%% operators in domains allows plans that act to gain knowledge, but the
%% approach assumes that such actions are deterministic and reliable, an
%% assumption that we relax.



%%No! They simply haven't been evaluated in PO settings. They may, or
%%may not struggle. They have sampling of traces, and that would
%%include observations, and therefore evolutions of beliefs. SSAT was
%%proposed by Littman for POMDPs. So the majercik stuff is perfectly
%%suited to POMDPs.

% Normally if we are going to compare with related work, we do
% actually *compare*. Why didn't you try those approaches? I think
% it's safe to say that FFR will struggle. Why would it even include
% in its plan an observational action that doesn't change the world?

%%
%% However, as we said in the introduction,
%% all these approaches struggle in partially observable domains as they
%% rely on being able to determine the state at all times.
