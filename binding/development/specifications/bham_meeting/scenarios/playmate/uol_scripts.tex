\documentclass{article}
\usepackage{verbatim}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mdwlist}
\usepackage{graphicx}

\title{UoL scenario specification}
\date{\today}
\author{CoSy}

\begin{document}
\maketitle
\begin{abstract}
Specification of the UoL scenario...
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Script -- level 1}
Some of the science demostrated through this scenario:
\begin{enumerate}
\item Tutor driven learning.
\item Tutor supervised and exploratory learning.
\item Unlearning.
\item Colearning.
\item Determination of salience.
\item Implicit learning.
\item Clarification.
\end{enumerate}

\noindent
Tutor driven learning.
\begin{enumerate}
\item \label{lvl1:step1} The human puts an object in front of the
  robot and retracts his arm.
  
\item \label{lvl1:step2} 
  H: ``This is a red triangular object.''\\
  R: ``OK.''

\item \label{lvl1:step3} H puts down a second object in front of the
  robot and retracts his arm.

\item \label{lvl1:step4} 
  H: ``This is a blue and triangular object.''\\
  R: ``OK.''

\item \label{lvl1:step5} The H reaches and retracts all the objects in
  the scene.

\item \label{lvl1:step6} The H puts three green objects and one yellow
  object down.

\item \label{lv1:step7}
  H: ``These are green objects.''\\
  R: ``OK.''

\item \label{lvl1:step8}
  H takes away the three given objects. \\
  OR \\
  H points to the yellow object.

\item \label{lvl1:step9}
  H: ``This object is not green.''\\
  R: ``OK.''

\item \label{lvl1:step10}
  H: ``Is this object green?''\\
  R: ``No.''

\item \label{lvl1:step11}
  H removes the yellow object.

\item \label{lvl1:step12}
  H puts down a green triangle.

\item \label{lvl1:step13}
  H: ``What is this object?''

\item \label{lvl1:step14}
  R: ``It is a green triangle.'' \\
  OR\\
  R: ``Is it a green triangle?''

\end{enumerate}

\noindent
Next, some examples on ambiguous reference to an object while
learning, and verbalizing learned knowledge.
\begin{enumerate}
\item \label{lvl1a:step1} H takes away all previous objects in the
  scene.

\item \label{lvl1a:step2} H puts a red triangle and a blue square
  together.

\item \label{lvl1a:step3} 
  H: ``This is a blue square.''\\

\item \label{lvl1a:step4} 
  R: ``Which thing do you mean?''

\item \label{lvl1a:step5} 
  H: ``The object on the right.''

\item \label{lvl1a:step6}
  R updates its representation.

\item \label{lvl1a:step7} 
  R: ``OK. So the object on the right is a blue square.''

\item \label{lvl1a:step8} 
  H picks up the red triangle and the blue square.

\item \label{lvl1a:step9}
  H puts down a blue square.
  
\item \label{lvl1a:step10}
  H: ``What color is this object?''

\item \label{lvl1a:step11}
  R: ``Is it a blue thing?''

\item \label{lvl1a:step12}
  H: ``Yes.''

\item \label{lvl1a:step13}
  H takes away the blue square.

\item \label{lvl1a:step14}
  H puts down the green triangle.

\item \label{lvl1a:step15}
  H: ``What do you see?''

\item \label{lvl1a:step16}
  R: ``I see a green thing. Is it a triangle?''
  
\item \label{lvl1a:step17}
  H: ``Yes.''

\item \label{lvl1a:step18}
  H picks up the green triangle.

\item \label{lvl1a:step19}
  H puts down a green circle.

\item \label{lvl1a:step20}
  R: ``I think this object is green, but what shape is it?''

\end{enumerate}

\noindent
Next, a look at the changes in the subarchitecture that accompany the
list of ambiguous reference steps above (just a few steps).
\begin{enumerate}
\item \label{lvl2a:step1} H removes all previous objects in the scene (trivial case:)

\item \label{lvl2a:step2} H puts a red triangle and a blue square
  together.

\begin{itemize}
\item \label{lvl2a:step2:detail1} VideoServer:VSA $\to$
  ChangeDetector:VSA $\to$ SceneChanged (stopped changing):VSA. \\
  Responsibility: UoL.

\item \label{lvl2a:step2:detail2} SceneChanged:VSA $\to$
  Segmentor:VSA $\to$ ROIs:VSA, SceneObjects:VSA. \\
  Responsibility: UoL.

\item \label{lvl2a:step2:detail3} SceneObjects:VSA $\to$
  BindingMonitor:VSA $\to$ Proxy:VSA. \\
  Responsibility: UoL/Bham (Binding Monitor needs to be resolved).

\item \label{lvl2a:step2:detail4} ROI:VSA $\to$
  FeatureExtractor:VSA $\to$ ROI:VSA. \\
  Responsibility: UoL.

\item \label{lvl2a:step2:detail5} Proxy:VSA $\to$ BindingComponent:BSA
  $\to$ Union:BSA. \\
  Responsibility: DFKI (Binding).

\item \label{lvl2a:step2:detail6} ROI:VSA (feature vector) $\to$
  Learner-Recognizer:VSA $\to$ ROI (attribute\_vector\_possible:VSA,
  attribute\_vector\_probable:VSA) $\to$ SceneObject (color,
  shape):VSA.\\
  Responsibility: UoL (Learner-Recognizer).

\item \label{lvl2a:step2:detail7} SceneObject:VSA $\to$
  BindingMonitor:VSA $\to$ Proxy:BSA (features added).

\item \label{lvl2a:step2:detail8} Proxy:BSA $\to$
  BindingComponent:BSA $\to$ Union:BSA.

\end{itemize}

\end{enumerate}

\noindent
Issues to be handled across the playmate demonstrator:
\begin{enumerate}
\item Proxy updating in Binding SA can fail if interrupted.
\item Learner-recognizer in VSA needs new synchronization/notification
  model.
\item Locking-invalidate-on-write inconsistency model.
\item Attribute vector needs to contain the posterior distributions.
\end{enumerate}


% \begin{figure}[ht]
% \centering
% \includegraphics[width=\linewidth]{example1_msc.png}
% \caption{
%   Some simple msc-graph can be generated to clarify interaction
%   between things in the the scenario. Use the
%   \texttt{../gen\_msc.sh}-script to generate pngs from all
%   msc-files. mscgen is documented here:
%   \texttt{http://www.mcternan.me.uk/mscgen/}. It's VERY simple}
% \label{fig:lvl1}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Script -- level 2}
Here is where the scripts are discussed in 'slightly' more detail...

\begin{enumerate}
\item \label{lvl2:step1} The human puts an object in front of the
  robot and retracts his arm.
  \begin{enumerate}
  \item \label{lvl2:step1:detail0} The robot tracks the hand and the
    object: recognizes ``put'' and ``retract'' actions.
  \item \label{lvl2:step1:detail1} The robot recognizes that the scene
    has changes.
  \item \label{lvl2:step1:detail2} Robot creates a (set of)
    placeholder(s) for the object(s).
  \end{enumerate}
  
\item \label{lvl2:step2} 
  H: ``This is a red triangular object.''\\
  R: ``OK.''
  \begin{enumerate}
  \item \label{lvl2:step2:detail} The robot recognizes the utterance +
    creates a representation for the context of the utterance.
  \item \label{lvl2:step2:detail2} The robot recognizes that it is
    being given a ``learning'' instruction.
  \item \label{lvl2:step2:detail3} It connects the thing being talked
    about with the thing being seen.
  \item \label{lvl2:step2:detail4} It initiates/triggers a learning
    action which creates the ``concepts'' of ``red'' and ``triangle''.
  \item \label{lvl2:step2:detail5} It generates an acknowledegment.
  \end{enumerate}

\item \label{lvl2:step3} H puts down a second object in front of the
  robot and retracts his arm.
  \begin{enumerate}
  \item \label{lvl2:step3:detail1} The robot tracks the object and the
    human hand + recognizes the ``put'' and ``retract'' actions.
  \item \label{lvl2:step3:detail2} The robot recognizes that the scene
    has been changed.
  \item \label{lvl2:step3:detail3} It attempts to recognize the shape,
    color of the new palceholder object.
  \item \label{lvl2:step3:detail4} 
  \end{enumerate}

\item \label{lvl2:step4} 
  H: ``This is a blue and triangular object.''\\
  R: ``OK.''
  \begin{enumerate}
  \item \label{lvl2:step4:detail1} As in Step~\ref{lvl2:step2} but it
    uses saliency to select the visual object being referred to (to
    learn about).
  \item \label{lvl2:step4:detail2} Also creates a new concept for
    ``blue''.
  \end{enumerate}

\item \label{lvl2:step5} The H reaches and retracts all the objects in
  the scene.
  \begin{enumerate}
  \item \label{lvl2:step5:detail1} The robot tracks hand and objects:
    ``reach for'', ``pull'' action recognized.
  \item \label{lvl2:step5:detail2} The robot analyzes the new
    ``blank'' scene.
  \end{enumerate}

\item \label{lvl2:step6} The H puts three green objects and one yellow
  object down.
  Analysis is similar to Step~\ref{lvl2:step1}.

\item \label{lv2:step7}
  H: ``These are green objects.''\\
  R: ``OK.''
  \begin{enumerate}
  \item \label{lvl2:step7:detail1} The robot does speech recognition
    and creates a representation of the context of the utterance.
  \item \label{lvl2:step7:detail2} The robot recognizes it has a
    learning assertion.
  \item \label{lvl2:step7:detail3} Connects the linguistic reference
    to the whole group.
  \item \label{lvl2:step7:detail4} Creates a concept for ``green'' and
    updates it three more times (one update erroneous -- yellow
    object).
  \item \label{lvl2:step7:detail5} Generates an acknowledgement.
  \end{enumerate}
  
\item \label{lvl2:step8} 
  H takes away the three given objects. \\
  OR \\
  H points to the yellow object.
  \begin{enumerate}
  \item \label{lvl2:step8a:detail1} Recognize the ``reach'' and
    ``pull'' actions.
  \item \label{lvl2:step8a:detail2} Re-analyzes the scenes -- matches
    the yellow object to the green concept.
  \end{enumerate}

  OR:
  \begin{enumerate}
  \item \label{lvl2:step8b:detail1} Robot recognizes the ``point''
    action.b
  \item \label{lvl2:step8b:detail2} The yellow placeholder becomes
    more salient.
  \end{enumerate}

\item \label{lvl2:step9}
  H: ``This object is not green.''\\
  R: ``OK.''
  See Step~\ref{lvl2:step7:detail1} and Step~\ref{lvl2:step7:detail2}.
  \begin{enumerate}
  \item \label{lvl2:step9:detail1} Connects the reference to the
    salient (yellow) object.
  \item \label{lvl2:step9:detail2} Updates the concept of green by
    removing the yellow component.
  \item \label{lvl2:step9:detail3} Generates an acknowledgement.
  \end{enumerate} 

\item \label{lvl2:step10}
  H: ``Is this object green?''\\
  R: ``No.''
  \begin{enumerate}
  \item \label{lvl2:step10:detail1} Parse the utterance as a question,
    and its context ``green object'' is represented.
  \item \label{lvl2:step10:detail2} The reference is bound to the
    salient visual object.
  \item \label{lvl2:step10:detail3} A goal is raised to answer the
    question.
  \item \label{lvl2:step10:detail4} The match to the concept of
    ``green'' is interrogated for the salient visual regions.
  \item \label{lvl2:step10:detail5} Robot returns the answer about a
    lack of match.
  \end{enumerate}

\item \label{lvl2:step11}
  H removes the yellow object.
  Analysis similar to Step~\ref{lvl2:step5}.

\item \label{lvl2:step12}
  H puts down a green triangle.
  Analysis similar to Step~\ref{lvl2:step1} or Step~\ref{lvl2:step3}.

\item \label{lvl2:step13}
  H: ``What is this object?''
  \begin{enumerate}
  \item \label{lvl2:step13:detail1} Comprehend the utterance and bind
    the reference to the visual object.
  \item \label{lvl2:step13:detail2} Raises a goal to answer the
    question.
  \end{enumerate}

\item \label{lvl2:step14}
  R: ``It is a green triangle.'' \\
  OR\\
  R: ``Is it a green triangle?''
  \begin{enumerate}
  \item \label{lvl2:step14:detail1} Generates an answer based on the
    recognized properties.
  \item \label{lvl2:step14:detail2} Generates the utterance.
  \end{enumerate}
\end{enumerate}

% \begin{figure}[!htcb]
% \centering
% \includegraphics[width=\linewidth]{example2_msc.png}
% \caption{
% A more detailed msc-graph could be used on this or next level...
% }
% \label{fig:lvl2}
% \end{figure}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Subarchitecture Level}

%%----------------------------------------------------------
\subsection{Step~\ref{lvl1a:step1}-\ref{lvl1a:step2}}
H takes away all previous objects in the scene.  H puts a red triangle
and a blue square together.

\subsubsection{Vision SA}
\begin{itemize}
\item Change detection.
\item ROIs, SOs (two of them).
\item No ``knowledge''.
\end{itemize}

\subsubsection{Binding SA}
\begin{itemize}
\item Proxies for ROIs and SOs.
\item Unions and relationships between the proxies for the objects.
\item Proxy for the discourse-referent blue square thing.
\end{itemize}

\subsubsection{Spatial SA}
\begin{itemize}
\item Proxies for ROIs and Sos.
\item Spatial relationships between the two objects.
\end{itemize}

\subsubsection{Comsys SA}
\begin{itemize}
\item A discourse-referent for the blue square thing.
\end{itemize}

Nick will fill in the subsequent steps...

%%----------------------------------------------------------
\subsection{Step~\ref{lvl1:step3}}




%%----------------------------------------------------------
\subsection{Step~\ref{lvl1:step4}}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Dependency Level}

\textit{
  What else is required to generate the above information and
  behaviour. Remember the already existing specs prepared prior to the
  meeting: \texttt{http://www.dfki.de/\~\ henrikj/doc\_test/specifications/main/html/}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Component Level}

\textit{
  First pass as describing the behaviours in terms of the components
  that are involved.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Responsibility Level}

Responsibilitites for the wide range of vision components (yes, we
have people assigned to tasks finally in the fourth year:)
\begin{enumerate}
\item VideoServer: Mohan.
\item Change Detector: Alen.
\item Segmentor: Alen.
\item Binding Monitor: Alen/Nick.
\item Feature Extractor: Alen.
\item Learner-Recognizer: Alen.
\item Discirminant Classifier: Nikodem.
\item Hand-tracker: Somboon.
\item Object Tracker: Somboon.
\item Action Recognizer: Somboon.
\item Pointing Analyzer: Peter.
\item Designing of IDLs: Jeremy, and only Jeremy!
\item Design of Synchronization: Nick.
\item Coordination over matlab/visual WM interface: Jeremy.
\end{enumerate}

\noindent
The entries in the various data structures in the visual WM:
\begin{itemize}
\item Region-Of-Interest (ROI):
  \begin{itemize}
  \item Time/frame number.
  \item 2D bounding box.
  \item Image raster.
  \item Feature vector.
  \item Color histogram (mean + standard deviation/range along each
    channel).
  \item Attribute-matrix-posterior (posterior distribution over the
    color/shape classes).
  \item Salience.
  \item Contour points (envelope of the objects in the ROI).
  \item Type (Hand/Thing).
  \end{itemize}
  
\item Scene Object (SOb):
  \begin{itemize}
  \item Color.
  \item Shape.
  \item 3D pose.
  \item Type (hand/thing).
  \end{itemize}

\item Scene Changed:
  \begin{itemize}
    \item Scene changing.
    \item Scene changed.
  \end{itemize}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

