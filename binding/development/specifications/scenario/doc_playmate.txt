/*! 
\page playmatescenario PlayMate Scenario

Draft PlayMate Scenario Script for Month 48

Some of the science that will be shown in this demonstration:

\li 1. Planning of sensing actions and visual processing.
\li 2. Planning of clarifying questions.
\li 3. Ability to recognise objects from a variety of views.
\li 4. Ability to recognise complex actions (composed of sequences of
actions).
\li 5. Ability to use learned categories for shape, colour and projective
spatial relations.
\li 6. Ability to understand which events in a sequence an utterance refers to.

It also requires some other abilities which are not scientific goals
previously studied by individual partners, but which will be essential
to an integrated system

\li 7.      Ability to reason about episodes and sequences of events.

Before the demo we could record movies of the robot learning about
shape, colour and projective relations using the objects to be used in
the demonstration.

Also, before the demo the games will be learned off-line, using the
complex action recognition system developed at Birmingham. Learning
on-line will be too challenging.

The objects to be used in the demonstration are:

\li \ref part1 : a red triangle, a blue triangle, a blue square, and a red square, a blue flag and a red flag
\li \ref part2 : Part 2: a car, and a second object (perhaps a phone)


NB In the shape game triangles go to the left, squares to the right.
In the colour game shapes go to the flag of their colour, wherever it is.

\section part1 Part 1: Script

The human sits next to the robot. There are two flags as landmarks
either side of the table in front of the robot. A red one is on the
left. A blue one is on the right.

\par Recognition of complex action sequences from vision

1       H: "I am playing a game."

2       R: "OK."

3       The human puts a red triangle in front of the robot.

4       He retracts his arm, and then reaches out, grasps the triangle,
and picks it up, or pushes it to the left flag.

5       The human withdraws the shape from the left flag.

6       H: "Which game am I playing?"

7       R: "I do not know, the shape game or the colour game."

8       The human puts a red square in front of the robot.

9       The human moves the red square to the right flag.

10      H: "Which game am I playing?"

11      R: "You are playing the shape game."

12      The human withdraws the red square from the right flag.


\par Ability to verbalise the rules of the game

13      The human puts a blue triangle in front of the robot.

14      H: "Where should the blue triangle go?"

15      R: "It should go next to the left flag."

16      The human moves the blue triangle to the left flag.

17      The human removes the blue triangle.

18      The human puts the blue square in front of the robot.

19      H: "Now I am playing the colour game."

20      R: "OK."

21      H: "Where does the blue square go?"

22      R: "It should go next to the blue flag."

23      H: "Where is the blue flag?"

24      R: "It is on the right (of the red flag)."

25      The human moves the blue square to the blue flag on the right.

26      The human removes the shape from the blue flag.


\par Ability to apply context specific game rules.

27      The human swaps around the blue and red flags.

28      The human puts the red square in front of the robot.

29      H: "Where does the red square go?"

30      R: "It should go next to the red flag."

31      H: "Where is the red flag?"

32      R: "It is on the right."

33      The human moves the red square to the red flag (now on the right.)

34      The human removes the shape from the red flag.


\par Ability to play the game, including the planning of sensory processing to support action

35      The human puts down the red triangle in front of the robot.

36      H: "Play the colour game."

37      The robot picks up the shape and puts it next to the red flag on the
right.

38      The human removes the shape from the flag.

39      Human puts the blue square in front of the robot.

40      H: "Play the shape game."

41      The robot picks up the shape and puts it next to the right hand (red)
flag.


\par Ability to plan sensory processing, recognise objects and to show object
persistence in memory

\section part2 Part 2: Script

1       The human shows the robot a car.

2       H: "This is a car."

3       The human turns the car in front of the robot.

4       The human puts the car behind the wall.

5       H: "Where is the car?"

6       R: "Behind the wall."

7       H: "What is behind the wall?"

8       The robot moves its arm camera to look behind the wall.

9       R: "I see a car and a blue thing."

10      R: "What is the blue thing?"

11      H: "It is a ball."


\par This Part 2 script requires some assumptions:

When learning appearance from multiple views, if this is done on-line it
requires movement of the object, but our current system is not able to
cope with movement of the object while performing (let alone learning)
recognition.

The robot can ask a clarification question here, but it is not pertinent
to the task.

The wall needs to be programmed into the robot’s model of the world a
priori, since we do not want to have to recognise it.

The planning would require the ability to reason about occlusion from
the world model.

*/