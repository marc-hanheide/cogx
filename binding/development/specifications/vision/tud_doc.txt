/*!
\page tud_spec Specification for the vision  subarchitecture (TUD)

\section scenario_tud Scenario

see other scenario: \ref main_scenarios

\section requirements_tud Requirements 
\li Detection of pretrained object classes

\section representations_tud Representations

TUD object detection components use structures to represent detections (bboxes) and  detection goals. Enumerations and VisionOnthology type information are used to enable (ontology type) dispatched communication via the WM and configuration of components.
Structure representations can be found in Vision.idl:

All detection results are represented by a BBox structure that is writte out to WM associated with some ontology type:

\code
struct ObjectLocation2D {
  BBox2D m_bbox; // 2D bounding box in image coordinates
  float m_confidence; // The certanity of the detection, between 0 and 1, 
                      // 1 being the most certain. Always higher than the specified threshold.
  FrameworkBasics::BALTTime m_time; // The time of the processed image
}; // struct ObjectLocation2D

\endcode

There is one detector goal type to request a single frame processing (read in from WM)

\code
enum ObjectClassDetectorGoalType {
  OCDGT_PULL_AND_DETECT // ObjectClassDetector goal: PULL an ImageFrame from the connected
                        // PullReceiver<Vision::ImageFrame> and run detection. 
};

const string OBJECT_CLASS_DETECTOR_GOAL_TYPE = "Vision:ObjectClassDetectorGoalType";

struct ObjectClassDetectorGoal{
      string ontologyid; // Goal to which detector
      ObjectClassDetectorGoalType type; // What is the goal
};
\endcode

Object Class Detectors can support runtime configuration i.e. enablig disabling of class specific detections

\code
enum ObjectClassDetectorConfigurationType {
  OCDCT_ENABLE_CLASS_DETCTION // enable class detection
  OCDCT_DISABLE_CLASS_DETCTION // disable class detection
};

const string OBJECT_CLASS_DETECTOR_CONFIGURATION_TYPE = "Vision:ObjectClassDetectorConfigurationType";

struct ObjectClassDetectorConfiguration{
      string detector_ontologyid; // detector component to be configured  (by ontology id)
      string obj_class_ontologyid; // which object class do we talk about?
      ObjectClassDetectorConfigurationType type; // enable or disable class detection ?
};
\endcode

Upon finishing processing a result structure is written out to WM in the presence of object hypotheses:

\code
const string OBJECT_CLASS_DETECTOR_RESULTS_TYPE = "Vision:ObjectClassDetectorResultsType";
// Indicated that the ObjectClassDetector completed a detection goal
// (new results are available:  ObjectLocation2D)
struct ObjectClassDetectorResults {
      string m_ontologyid; // indicates which detection is finished, allows simoultanous run
                           // of several ObjcetClassDetector
      long m_detections; // Number of detections
      FrameworkBasics::BALTTime m_time; // The time of the image on which the detector run
};
\endcode

Definitions in VisionOnthology embed types from Vision.idl and add types to distinguish between different object classes:
\code
const string VisionOntology::PERSON_2DLOCATION_TYPE = "Vision:Person2DLocation";

// go for one OBJECT_2DLOCATION_TYPE? with obj class as string* in 2d location?
const string VisionOntology::CAR_2DLOCATION_TYPE = "Vision:Car2DLocation"; 
const string VisionOntology::MUG_2DLOCATION_TYPE = "Vision:Mug2DLocation";
//... etc

const string VisionOntology::OBJECT_CLASS_DETECTOR_GOAL_TYPE = Vision::OBJECT_CLASS_DETECTOR_GOAL_TYPE;
const string VisionOntology::OBJECT_CLASS_DETECTOR_CONFIGURATION_TYPE = Vision::OBJECT_CLASS_DETECTOR_CONFIGURATION_TYPE;
const string VisionOntology::OBJECT_CLASS_DETECTOR_RESULTS_TYPE = Vision::OBJECT_CLASS_DETECTOR_RESULTS_TYPE;
\endcode


\par Action: 

\section components_tud Components TUD

All omponents process images from the Vision.SA video server in a pipes & filters fashion. Image data processing
happens continously  or on request signaled via the WM (initialization in cast configuration file). All detection results are stored into WM and are cleaned before processing a consecutive image frame. Current implementations assume are based on a window sliding approache using HoG as descriptor and a linear SVM for classification. Right now we assume all models are (pre) trained "offline".

\subsection PeopleDetector People Detector
\li Functionality: Detects people im images pulled from the video server. Detector can run in triggered or continous mode.

\li Triggered by: ObjectClassDetectorGoal struct with goal type OBJECT_CLASS_DETECTOR_GOAL_TYPE and ontologyid set to CAR_2DLOCATION_TYPE. 

\li Behaviour: Writes a struct ObjectClassDetectorResults of ontology type OBJECT_CLASS_DETECTOR_RESULTS_TYPE to signal the number of hypotheses found in current image. The struct member m_ontologyid is set to PERSON_2DLOCATION_TYPE. Hypotheses are stored in WM and deleted in a consecutive detection cycle.

\li CAST calls: getWorkingMemoryEntries, addToWorkingMemory, deleteFromWorkingMemory 

The PeopleDetector exists as a separate component (and is not part of the General Object Class Detector) due to its forthcoming GPU re-implementaion.

\subsection ObjectClassDetector Generic Object Class Detector
\li Functionality: Detects instances of object classes in images pulled from the video server. Detector can run in triggered or continous mode.

\li Triggered by: ObjectClassDetectorGoal struct with goal type OBJECT_CLASS_DETECTOR_GOAL_TYPE and ontologyid set to any object class type other than CAR_2DLOCATION_TYPE

\li Behaviour: Writes ObjectClassDetectorResults struct(s) of ontology type OBJECT_CLASS_DETECTOR_RESULTS_TYPE for each active object class detector to signal the number of hypotheses found in current image. The struct member m_ontologyid is set to the appropriate *OBJECTCLASSNAME*_2DLOCATION_TYPE.

\li CAST calls: getWorkingMemoryEntries, addToWorkingMemory, deleteFromWorkingMemory

\subsection ObjectClassInspector Object Class Inspector
\li Functionality: A simple component that requests a detection from a detector in an endless loop. 

\li Triggered by: 

\li Behaviour: Triggers a Detector component by writning a ObjectClassDetectorGoal struct with  OCDGT_PULL_AND_DETECT as goal type an the object class (detector) VisionOntology type as ontologyid. After a ObjectClassDetectorResults struct is recieved from WM image data is pulled from the Detector component acting as a video server (proxy) and  all  ObjectLocation2D structs of the object class VisionOntology type are visualized via OpenCV on screen.
s
\li CAST calls: getWorkingMemoryEntries, addToWorkingMemory

(It is possible to run the ObjecClassInspectorExecution as a Listener. However, his leads to synchrnoisation issues in case of the object detector running in continous mode.)

\subsubsection AffordanceRecorder Affordance Recorder


\section  processes Processes

\subsection  DetectorInspectorProcess Detector-Inspector Process 
OCI is ObjectClassInspector, OCD is ObjectClassDetector 
\msc

	hscale = "1.4";
	OCI, "g:DetectionGoal", "r:DetectorResult", "l:ObjectLocation", OCD;
	OCI->"g:DetectionGoal" [label="<<create>>"];
	"g:DetectionGoal"->OCD [label="wmc(ADD)"];
	OCD=>"g:DetectionGoal" [label="get(g)"];
	OCD<<"g:DetectionGoal" [label="g"];
        ... [label = "OCD pulls image from VideoServer and detects objects"];
        OCD->"l:ObjectLocation" [label="<<create>>"];
        "l:ObjectLocation"->OCI [label="wmc(ADD)"];
        OCD->"r:DetectorResult" [label="<<create>>"];
        "r:DetectorResult"->OCI [label="wmc(ADD)"];
        OCI->"r:DetectorResult" [label="get(r)"];
        OCI<<"r:DetectorResult" [label="r"];
        OCI->"r:DetectorResult" [label="get(l)"];
        ... [label = "OCI pulls image from OCD (acting as VideoServer) plots detections and displays image"];

\endmsc


*/
