/*!
\page eventDetect_spec Specification for visual event detector (BHAM)

\section scenario Scenario

See other scenario: \ref main_scenarios

\section requirements Requirements

\li ev.1: Able to track 3D locations of a pre-defined set of objects
(e.g., hands, landmarks such as flags).
\li ev.2: Able to track 3D locations of objects of a 
various combination of shapes and colours.
\li ev.3: Able to classify shapes and colours
and obtain a representation of manipulable objects.
\li ev.4: Able to obtain a representation of
object manipulation behaviour of the user.
\li ev.5: Able to predict an action sequence
from partial observation.

\section representations Representations

\par ImageFrame : 
A representation of image as defined in the IDL file.

\code
// image format is always BGR24
struct ImageFrame {
  long           m_width;
  long           m_height;
  ImageData      m_image;
  FrameworkBasics::BALTTime  m_time;
  long           m_camNum;
};
\endcode

\sa Vision::ImageFrame

\par Scene object:
As required in ev.1, ev.2 and ev.3, 
a representation of an object 
includes a name used to uniquely identify the object,
a type from a pre-defined list (e.g., hand, flag landmark), 
and a set of labels that specify shape and colour 
from a pre-defined list.
Also, as required by ev.1 and ev.2, we keep track of 
how the object has been moved at each time frame
by its 3D pose and 3D bounding box.

All these have been defined in IDLs. 

\code
struct SceneObject {
    BBox3D           m_bbox;
    Math::Pose3D     m_pose;
    FrameworkBasics::BALTTime    m_time;

    /* 
     * Members for linguistically assigned values.
     */
    IntWithConfidence    m_color;
    IntWithConfidence    m_shape;
    IntWithConfidence    m_generic;

    StringWithConfidence m_label;
    sequence<Surface>    m_surfaces;
  };
\endcode

\sa Vision::SceneObject

\par Tracking state:
A tracking state consists of a list of scene objects
that change their poses at each time frame.
A struct that represents this list is defined 
in the IDL file as \c AttendedObjectList.

\code
struct AttendedObjectList {
      sequence <string> m_memoryIDList;
      FrameworkBasics::BALTTime  m_time; 
};
\endcode

\sa Vision::AttendedObjectList


\par Action step: 
An action step consists of a name that is used to identify the 
action, and a series of parameters. These parameters include
the working memory addresses of the object that is being 
manipulated (or the target) and the hand 
(or the source of action), a boolean variable (flag) 
that indicates whether the action has completed, 
the start and end times (or a progressing time, 
if the action has not yet completed). 
Also, the action step has pre-condition and post-condition
states which are represented by the ActionState struct.

\code
struct ActionStep {
      string        m_actionName;
      string        m_actionSourceMemoryID; // hand id
      string        m_actionTargetMemoryID; // object id
      boolean       m_bCompleted;
      FrameworkBasics::BALTTime  m_startTime;
      FrameworkBasics::BALTTime  m_ProgressingTime;
      ActionState   m_precondState;
      ActionState   m_goalState;
};
\endcode

\par Action state:
An action state contains a list of features
derived from the properties (and spatio-temporal relations) 
of the source and target objects.
Each action feature contains a name of property (or relation) 
and its value.

\code
struct ActionFeature {
  PropertyType    m_featureName;
  float           m_featureValueRange;
};
  
typedef sequence <ActionFeature> ActionFeatureList;

struct ActionState {
  ActionFeatureList m_setOfFeatures;
};
\endcode

\par Behaviour:
A behaviour can be used to represent a general behaviour
of a user or a learned behaviour in a specific context
(e.g., a game). It is identified by a name 
(e.g., "shape game" or "colour game"),
and contains an ordered sequence of action steps.

\code
struct Behaviour {
    string        m_name;
    sequence <ActionStep> m_steps;
};
\endcode

\section components Components

\subsection video_server Video Server Component(VSC) 
\par Functionality: 
	Creates an abstraction of camera devices, and
        provides access to images captured from the cameras. 
\par Triggered by: 
	Image acquisition does not require a trigger.
\par Listen for:
        A request for access to an image from a specific camera
        can be made by \c VideoClientProcess::GetImage(int camNum).
\par Behaviour: 
        VideoServer waits for a request to access an image from
        a specific camera ID, and then respond to the request
        with ImageFrame. 

\par Requirements satisfied: 
	ev.1, ev.2

\subsection object_tracker Object Tracker Component(OTC)     
\par Functionality: 
	Tracks objects based on color, motion or visual patterns.
\par Triggered by: 
        OTC sends a request to VideoServer for access to images
        to process at a specific interval (typically 10 fps.).
	Tracking routines are activated upon the return of 
	the requested ImageFrame.
\par Behaviour: 
	Extracts ImageData from ImageFrame struct,
      	and runs a tracking routine based on image motion or using
        color and other pattern-based models for a pre-defined 
	set of objects.
        The results (object poses, bounding boxes, 
	and, if available, color ID's and labels) are written
        to SceneObject struct, which is then written back to working memory.
	After losing tracks of an object for a specific number of frames 
	the corresponding SceneObject will be deleted from the
	working memory.

\li \c GetImage: \c ImageFrame(m_image)
\li \c addToWorkingMemory: \c SceneObject(m_label), \c AttendedObjectList
\li \c overwriteWorkingMemory: \c SceneObject(m_label), \c AttendedObjectList
\li \c deleteFromWorkingMemory: 

\par Requirements satisfied: 
	ev.1, ev.2

\subsection property_classifier Object Property Classifier Component(OPCC) 
\par Functionality: 
	Classify the shape and color properties of an obejct
	into a set of pre-defined types (e.g., square, triangular).
\par Triggered by: 
	To be filled by Mohan? 
\par Behaviour: 
        To be filled by Mohan?
\par Requirements satisfied: 
	ev.3

\subsection event_detector Event Detector Component (EDC) 
\par Functionality: 
	Generates a representation of the observed human behaviour. 
\par Triggered by: 
	\c wmc: \c Vision::AttendedObjectList, 
        \c WorkingMemeryOperation.ADD, \c UPDATED, local
\par Behaviour: 
	The event analysis process in event detection component 
	is triggered by the addition or update of 
	\c AttendedObjectList by ObjectTracker component (OTC).
	EDC first updates the trajectories of all relevant objects.
	Spatio-temporal properties of the trajectories are 
	then computed and analysed with foctorized, abstract
	Hidden Markov Model (FA-HMMs) in order to segment the
	trajectories into a sequence of action steps.
	We represent each type of unique human behaviour 
	as a FA-HMM. EDC will compute the most likely behaviour
        and write the results to the local WorkingMemory. 
 
\par Attention:
        Currently, once the Behaviour is written in the working memory,
        we do not remove it. 

\li \c addToWorkingMemory: \c ActionStep, \c ActionState, \c ActionFeatures, \c Behaviour
\li \c overwriteWorkingMemory: \c ActionStep, \c ActionState, \c ActionFeatures, \c Behaviour
\li \c deleteFromWorkingMemory: 

\par Requirements satisfied: 
	ev.4 and ev.5

\section processes Processes

\subsection event_detection_process Event Dectection Process 

OTC = Object Tracking Process, 
VSC = Video Server Process, 
OPCC = Object Property Classifing Process,
EDC = Event Detection Process

"so" = SceneObject,
"so_n" = nth SceneObject,
"aol" = AttendedObjectList,
"as_n" = nth ActionStep,
"beh" = Behaviour

\msc
hscale = "1";
OTC, VSC, "so_1", "..." ,"so_n", "aol", OPCC, "as_1", "...", "as_n", "beh", EDC;
OTC=>VSC [label="GetImage()"];
OTC<<VSC [label="ImageFrame"];
OTC->"so_1" [label="<<create>>"];
"so_1"->OPCC [label="wmc(ADD)"];
"so_1"<=OPCC [label="get(so_1)"];
"so_1">>OPCC [label="so_1"];
... [label = "OTC tracks and creates scene objects"];
OTC->"so_n" [label="<<create>>"];
"so_n"->OPCC [label="wmc(ADD)"];
"so_n"<=OPCC [label="get(so_n)"];
"so_n">>OPCC [label="so_n"];
... [label = "OPCC classifies the properties of scene objects"];
"so_1"<-OPCC [label="<<overwrite>>"];
... [label="OPCC overwrites so's in WorkingMemory"];
"so_n"<-OPCC [label="<<overwrite>>"];
OTC->"aol" [label="<<create>>"];
"aol"->EDC [label="wmc(ADD)"];
"aol"<=EDC [label="get(aol)"];
"aol">>EDC [label="aol"];
"so_1"<=EDC [label="get(so_1)"];
"so_1">>EDC [label="so_1"];
... ;
"so_n"<=EDC [label="get(so_n)"];
"so_n">>EDC [label="so_n"];

... [label="EDC runs event analysis routines"];
"as_1"<-EDC [label="<<create>>"];
...;
"as_n"<-EDC [label="<<create>>"];
"beh"<-EDC [label="<<create>>"];
\endmsc

*/
