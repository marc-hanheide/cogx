


%%  and
%% using various techniques to manage the large state
%% space

%% \citeauthor{hippo-jnl}~(\citeyear{hippo-jnl}) take this
%% approach in a 

%%  ---essentially the idea that
%% it does not matter what the value of the variable you are trying to
%% observe is---

Addressing task and observation planning specifically, there have been
a number of recent developments where the underlying problem is
modelled as a POMDP.
%%
For vision algorithm
selection,~\citeauthor{hippo-jnl}~(\citeyear{hippo-jnl}) exploit an
explicitly modelled hierarchical decomposition of the underlying
POMDP. \citeauthor{doshi08:pref_elic}~(\citeyear{doshi08:pref_elic})
represent a preference elicitation problem as a POMDP and take
advantage of symmetry in the belief-space to exponentially shrink the
state-space. Although we have been actively exploring
the \citeauthor{doshi08:pref_elic} approach, those exploitable
symmetries are not present in problems we consider due to the task
planning requirement.
%%
Also, our approach is in a similar vein to {\em dual-mode}
control~\cite{cassandra96actingunder}, where planning switches between
entropy and utility focuses.

%% serial planning in
%% problem determinisations underlines strategies to goal achievement,
%% and 

%% in our case we use serial
%% planning in a determinisation of the underlying process to guide DT
%% sessions, which typically act to reducing entropy.


%% entropy reduction is targeted by planning in an abstract process which
%% is informed by one execution trace ---computed by a {\em classical}
%% planner--- and the underlying belief-state.


There has also been much recent work on scaling offline approximate
POMDP solution procedures to medium-sized instances. Recent
contributions propose more efficient belief-point sampling
schemes~\cite{kurniawati:etal:2010,shani:etal:08}, and factored
representations with procedures that can efficiently exploit
structures in those
representations~\cite{brunskill:russell:2010,shani:etal:2008}. Offline
domain independent systems scale to {\em logistics} problems with
$2^{22}$ states~\cite{shani:etal:2008}, taking over an hour to
converge, and around 10 seconds on average to perform each Bellman
backup. \citeauthor{brunskill:russell:2010} are able to solve problems
with approximately $10^{30}$ states, by further exploiting certain
problem features -- E.g., problems where no actions have negative
effects.
%%
Moving someway towards supporting real-time decision making, recent
online POMDP solution procedures have been developed which leverage
highly approximate value functions -- computed using an offline
procedure -- and heuristics in forward
search~\cite{ross:etal:2008}. These approaches are applicable in
relatively small problems, and can require
expensive \emph{problem-specific} offline processing in order to yield
good behaviours.
%%
A {\em very} recent and promising online approach for
larger POMDPs employs Monte-Carlo sampling to break the curse of
dimensionality in situations where goal reachability is {\em easily}
determined~\cite{silver:veness:2010}. 
%%
Our approach can also be thought of as an online POMDP solver that
uses a sequential plan to guide the search, rather than (e.g.,
Monte-Carlo) sampling. Also, compared to most online POMDP procedures, which
replan at each step, our approach involves relatively little replanning.

%% Our approach requires minimal DT replanning,
%% preferring

%% Also, our approach will execute a few
%% actions (as much as it can before an assumption is found to be true or
%% false) before needing to plan again, rather than planning after each
%% step.





%% Moving someway towards supporting real-time decision making, recent
%% online POMDP solution procedures have been developed which leverage
%% highly approximate value functions -- computed using an offline
%% procedure -- and heuristics in forward
%% search~\cite{ross:etal:2008}. These approaches are applicable in
%% larger problems (\cite{ross:etal:2008} includes experiments in a domain
%% with around 12 thousand states), but the fact they often require
%% expensive \emph{problem-specific} offline processing in order to yield
%% good behaviours means they are impractical in problems as large as ours.
%% %%
%% A recent and promising online approach for
%% larger POMDPs employs Monte-Carlo sampling to break the curse of
%% dimensionality in situations where goal reachability is {\em easily}
%% determined~\cite{silver:veness:2010}. Our approach can also be thought of
%% as an online POMDP solver, but uses the sequential plan to guide the
%% search
%% for a decision-theoretic plan, rather than Monte-Carlo sampling. In
%% addition, our approach will execute a few actions (as much as it can
%% before
%% an assumption is found to be true or false) before needing to plan again,
%% rather than planning after each step.

%% [have a look at the bit in parentheses above, I'm not sure I quite
%% characterised how much plan it executes before replanning satisfactorally]






In the direction of leveraging {\em classical} systems/approaches for
planning under uncertainty, the most highlighted system to date has
been \system{FFR$_a$}~\cite{yoon:etal:2007}; The winning entry from
the probabilistic track of the 2004 International Planning
Competition.  In the continual paradigm, \system{FFR$_a$}
uses \system{FF} to compute sequential plans and execution traces.
%%
More computationally expensive approaches in this vein combine
sampling strategies on valuations over {\em runtime variables} with
deterministic planning procedures~\cite{yoon:etal:2008}. %% The outcome is typically a more
%% robust sequential plan, or contingent
%% plan~\cite{majercik:2006}. 

Also leveraging deterministic planners in problems that feature
uncertainty, \system{Conformant-FF}~\cite{hoffmann:brafman:2006} and
$T_0$~\cite{palacios:geffner:2009} demonstrate how conformant planning
-- i.e., sequential planning in unobservable worlds -- can be modelled
as a deterministic problem, and therefore solved using sequential
systems. In this conformant setting, advances have been towards
compact representations of beliefs amenable to existing best-first
search planning procedures, and lazy evaluations of beliefs. We
consider it an appealing future direction to pursue conformant
reasoning during the sequential sessions we proposed. Most recently
this research thread has been extended to contingent planning in fully
observable non-deterministic environments~\cite{albore:etal:2009}.
