% coming soon


We have implemented our switching continual approach in MAPSIM
environment~\cite{brenner:nebel:jaamas09}. Our implementation is able
to use several underlying planning systems. We have also extended the
MAPSIM system so that it can parse DTPDDL, and perform successive
estimation of the underlying belief-state using the
\system{dlib-ml}~\cite{king:2009} for inference.  In this evaluation
we have use our own version of Fast Downward~\cite{fast-downward} for
sequential sessions. We have extended that system to support actions
with success probabilities. In our evaluation Fast Downward is run
with the cyclic causal graph heuristic using an A* search or weighted
A* (with weight 5). We use A* for easy problems and WA* for more
difficult problems where A* was ineffective. Contingent sessions use
our own forward search procedure. 


\Omit{ We then perform multiple tests with different limits for the
  belief-space size in contingent sessions.  Higher limits should
  cause longer planning times but be beneficial to plan quality as
  more contingencies can be taken in to account by the POMDP planner.
}

In order to evaluate our system, we have also implemented a baseline
approach in MAPSIM. Rather than invoking a contingent session when a
switching action $\switchAction$ is scheduled for execution, the
baseline simply executes one action that can trigger a sensing outcome
determined by the precondition of $\switchAction$, and replans in the
resulting belief-state.




%% executes switching actions and replans in the
%% resulting belief state.

%% but instead of
%% creating an observation problem for the decision theoretic planner it
%% will just execute one sensing action -- assuming that this action will
%% confirm its assumption.

To test our approach we use a robot exploration domain based on a that
from our physical robotic system. Here, a robot is exploring an office
or living environment, and trying to report the locations of objects
to their owner.

\begin{figure}[h]
  \centering
  \input{figures/dora}
  \caption{A exploration domain with three rooms and 13 places. The
    robot is in in the centre of room A}
\label{fig:dora2}
\end{figure}
An instance of this domain is shown in figure \ref{fig:dora2}. Basic
types of element are{\tt rooms}, {\tt places} and {\tt
  objects}. Places are topological map nodes that occur in rooms. and
Objects (including the robot) are always located at a place. The robot
can move around the rooms via connections between places given by the
{\tt connected} predicate. Each room has a (possibly unknown) {\em
  category/} (e.g. kitchen, office, living room) and depending on this
category, objects are placed inside the rooms.

The robot can find out if an object is at a certain place by executing
the {\tt look-for-object} action. Moreover, the contents of a room
indicates its category, and certain objects are more likely to be
located in rooms of certain categories. For example, a box of
cornflakes is more likely to be located in the kitchen than the
office. The {\tt look-for-object} might result in a positive
perception if the object is there. Some objects are harder to detect
than others, so that an instantaneous positive detection of the object
is not proof positive that it is there. Additionally, if the robot is
in the presence of a human, it can ask what type of room they are
currently in, however conducting a dialogue is more costly than
running a vision algorithm (cost of 8 vs costs of 3).

We perform experiments on tasks of several sizes. The robot's
objective is to find one or more objects and report back their
position to a person. In order to determine the impact of sensor
reliability in a comparison with the baseline, we also ran tests on
identical problems but changed the sensor model for the target
objects: the probability for perceiving the object if it was there
went from 0.9 in the easiest case to 0.65 and 0.4 in the average and
hard cases respectively. In addition, we wanted to test how our system
performed on tasks requiring indirect sensing, so we gave the planner
rewards for visiting a certain type of room (e.g. kitchen or
office). We did not place any humans in those scenarios, so the only
way of determining the room category was by looking for objects
typical for that room type. As this indirect reasoning is a tasks that
cannot be performed by the continual planner alone, we did not run the
baseline system on those problems.



In our evaluation we run 50 simulations in each configuration. The
samples for the true initial state are drawn from the same
distribution that is used for planning, therefore the planer and
simulation models are in exact correspondence. Not all problems have a
solution, and we explore whether or not detection of the non-existence
of a solution is important in stochastic domains.
%%
We also perform multiple tests
with different limits for the belief-space size in contingent
sessions.  Higher limits should cause longer planning times but be
beneficial to plan quality as more contingencies can be taken in to
account by the POMDP planner.


Using a satisficing, optimistic serial planner and using continual
planning makes optimising for the expected reward difficult. The
continual planner will in general be overly optimistic regarding the
remaining costs to a goal while being overly pessimistic regarding the
probability of reaching it (as it only considered one trace). This
means that setting the reward function to non-extremal setting had
little effect on the resulting planner behaviour. For this reason, we
chose not to use the expected reward as a metric for our results, as
that information would not have been informative. Instead we show the
average costs of the plan and the success rate (as a ratio between
solved and solvable problems) separately.

\begin{figure}[h!]
  % \centering
  % \includegraphics{dora1-time}\hfill
  % \vspace{2mm}
  \includegraphics{dora2-time}\hfill
  \vspace{2mm}
  \includegraphics{dora3-time}\hfill
  \vspace{2mm}
  \includegraphics{dora4-time}\hfill
  \vspace{2mm}
  \includegraphics{dora56-time}\hfill
  \vspace{2mm}
  \includegraphics{dora-cat-time}\hfill
  \caption{Average runtime}
  \label{fig:results-time}
\end{figure}

\begin{figure}[h!]
  % \centering
  % \includegraphics{dora1-quality}\hfill
  % \vspace{2mm}
  \includegraphics{dora2-quality}\hfill
  \vspace{2mm}
  \includegraphics{dora3-quality}\hfill
  \vspace{2mm}
  \includegraphics{dora4-quality}\hfill
  \vspace{2mm}
  \includegraphics{dora56-quality}\hfill
  \vspace{2mm}
  \includegraphics{dora-cat-quality}\hfill
  \caption{Average plan costs and number of successful runs}
  \label{fig:results-quality}
\end{figure}

The graphs in figure \ref{fig:results-time} show the average planning
times. Not surprisingly, the time for contingent planning increases
steeply as we have more states with non-zero probability (i.e., less
abstract) in $\bstate_0$. For small initial configurations, the cost
of contingent planning is compensated by the decrease of time spent in
Fast Downward.

Figure \ref{fig:results-quality} shows the average costs of the
executed plans as well as the percentage of solvable tasks that were
actually solved by the planner. For objects that can be easily
detected there is little gain in using a decision-theoretic planner,
as the greedy sensing approach by the baseline continual planner is
obviously sufficient here. With decreasing sensor reliability the more
sophisticated observation strategies of contingent planning pay off:
while the resulting plans are still longer on average, the impact on
the number of solved tasks was much smaller than for the baseline
system.

Less aggressive abstraction of the initial belief space results in
longer runtimes. We find that abstraction has little impact on plan
costs and success rate in our scenario. Increasing the size of the
initial abstract belief beyond 50 states rarely pays off, because
while additional information may facilitate better plans, the indirect
sensing tests report the same result. Here, we only really see an
impact in terms of the runtime of contingent planning. The relatively
high success rate even with small belief spaces indicates the
effectiveness of using conditional entropy to guide abstraction
refinement.

% We believe that a part of the improvement is due to the segmentation of
% the plan into several subtask, essentially performing hierarchical
% planning. Especially when the continual planner performs badly this is
% a huge gain.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "moritz_2011"
%%% End: 
