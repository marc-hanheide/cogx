/**
 * @author Michael Zillich
 *
 * @version $Id: Camera.h,v 1.2 2009/01/09 17:21:28 mz Exp mz $
 */

#include <cassert>
#include <cmath>
#include <cfloat>
#include <sstream>
#include <iostream>
#include <opencv/cvaux.h>
#include "cogxmath.h"
#include "CDataFile.h"
#include "VideoUtils.h"
#include "StereoCamera.h"

namespace cast
{

using namespace std;
using namespace cogx;
using namespace cogx::Math;
using namespace Video;

static void ReadMat33(istream &s, double M[3][3])
{
  s >> M[0][0] >> M[0][1] >> M[0][2]
    >> M[1][0] >> M[1][1] >> M[1][2]
    >> M[2][0] >> M[2][1] >> M[2][2];
}

static void ReadMat34(istream &s, double M[3][4])
{
  s >> M[0][0] >> M[0][1] >> M[0][2] >> M[0][3]
    >> M[1][0] >> M[1][1] >> M[1][2] >> M[1][3]
    >> M[2][0] >> M[2][1] >> M[2][2] >> M[2][3];
}

StereoCamera::StereoCamera()
{
  maxDistortion = .5;
  mapx[LEFT] = mapx[RIGHT] = 0;
  mapy[LEFT] = mapy[RIGHT] = 0;
  sx = sy = 1.;
  inImgSize.width = 0;
  inImgSize.height = 0;
  //matchAlgorithm = SEMI_GLOBAL_BLOCK_MATCH;
  matchAlgorithm = BLOCK_MATCH;
  stereo_bm_state = cvCreateStereoBMState(CV_STEREO_BM_BASIC);
  stereoBM = new cv::StereoBM();
  stereoSGBM = new cv::StereoSGBM(0, 64, 21);  // HACK: disparity range
}

StereoCamera::~StereoCamera()
{
  // TODO: free remapping images!
  cvReleaseImage(&mapx[LEFT]);
  cvReleaseImage(&mapx[RIGHT]);
  cvReleaseImage(&mapy[LEFT]);
  cvReleaseImage(&mapy[RIGHT]);
  cvReleaseStereoBMState(&stereo_bm_state);
  delete stereoBM;
  delete stereoSGBM;
}

/**
 * @brief Read calibration from xml-file (for single camera)
 * @param filename Filename of left or right calib-file
 * @param side 0 for left / 1 for right side
 * @param usePose Use pose from calibration file or use identity matrix
 */
void StereoCamera::ReadFromXML(const string &filename, int side, bool usePose)
{
  cv::FileStorage calibFile(filename, cv::FileStorage::READ);

  CvMat *size = (CvMat*)calibFile["imgsize"].readObj();
  CvMat *intrinsic = (CvMat*)calibFile["intrinsic"].readObj();
  CvMat *distortion = (CvMat*)calibFile["distortion"].readObj();
  CvMat *proj = (CvMat*)calibFile["projection"].readObj();
  CvMat *rect = (CvMat*)calibFile["rotation"].readObj();
  CvMat *tvec = (CvMat*)calibFile["tvec"].readObj();
  CvMat *rmat = (CvMat*)calibFile["rmat"].readObj();

  cam[side].width = (int) cvmGet(size, 0, 0);
  cam[side].height = (int) cvmGet(size, 1, 0);
  
  cam[side].fx = cvmGet(intrinsic, 0, 0);
  cam[side].fy = cvmGet(intrinsic, 1, 1);
  cam[side].cx = cvmGet(intrinsic, 0, 2);
  cam[side].cy = cvmGet(intrinsic, 1, 2);
  
  cam[side].k1 = cvmGet(distortion, 0, 0);
  cam[side].k2 = cvmGet(distortion, 0, 1);
  cam[side].t1 = cvmGet(distortion, 0, 2);
  cam[side].t2 = cvmGet(distortion, 0, 3);
  if(distortion->rows == 5 || distortion->cols == 5)
    cam[side].k3 = cvmGet(distortion, 0, 4);
  
  cam[side].proj[0][0] = cvmGet(proj, 0, 0);
  cam[side].proj[0][1] = cvmGet(proj, 0, 1);
  cam[side].proj[0][2] = cvmGet(proj, 0, 2);
  cam[side].proj[0][3] = cvmGet(proj, 0, 3);
  cam[side].proj[1][0] = cvmGet(proj, 1, 0);
  cam[side].proj[1][1] = cvmGet(proj, 1, 1);
  cam[side].proj[1][2] = cvmGet(proj, 1, 2);
  cam[side].proj[1][3] = cvmGet(proj, 1, 3);
  cam[side].proj[2][0] = cvmGet(proj, 2, 0);
  cam[side].proj[2][1] = cvmGet(proj, 2, 1);
  cam[side].proj[2][2] = cvmGet(proj, 2, 2);
  cam[side].proj[2][3] = cvmGet(proj, 2, 3);  

  // NOTE: stereo camera rect matrix is the rotation matrix of real to ideal.
  // So to get from ideal to real, this will have to be inverted.
  cam[side].rect[0][0] = cvmGet(rect, 0, 0);
  cam[side].rect[0][1] = cvmGet(rect, 0, 1);
  cam[side].rect[0][2] = cvmGet(rect, 0, 2);
  cam[side].rect[1][0] = cvmGet(rect, 1, 0);
  cam[side].rect[1][1] = cvmGet(rect, 1, 1);
  cam[side].rect[1][2] = cvmGet(rect, 1, 2);
  cam[side].rect[2][0] = cvmGet(rect, 2, 0);
  cam[side].rect[2][1] = cvmGet(rect, 2, 1);
  cam[side].rect[2][2] = cvmGet(rect, 2, 2);
  
  if(usePose)
  {
    cam[side].pose.pos.x = cvmGet(tvec, 0, 0);
    cam[side].pose.pos.y = cvmGet(tvec, 1, 0);
    cam[side].pose.pos.z = cvmGet(tvec, 2, 0);
    cam[side].pose.rot.m00 = cvmGet(rmat, 0, 0);
    cam[side].pose.rot.m01 = cvmGet(rmat, 0, 1);
    cam[side].pose.rot.m02 = cvmGet(rmat, 0, 2);
    cam[side].pose.rot.m10 = cvmGet(rmat, 1, 0);
    cam[side].pose.rot.m11 = cvmGet(rmat, 1, 1);
    cam[side].pose.rot.m12 = cvmGet(rmat, 1, 2);
    cam[side].pose.rot.m20 = cvmGet(rmat, 2, 0);
    cam[side].pose.rot.m21 = cvmGet(rmat, 2, 1);
    cam[side].pose.rot.m22 = cvmGet(rmat, 2, 2);
  }
  else setIdentity(cam[side].pose);

  inImgSize.width = cam[side].width;
  inImgSize.height = cam[side].height;
  sx = 1.;
  sy = 1.;
}

/**
 * Read calibration from a file generated by SVS.
 * NOTE: the 'frame' parameter in the SVS calibration file is ignored. It is
 * typically 1 anyway.
 */
bool StereoCamera::ReadSVSCalib(const string &calibfile)
{
  printf("StereoCamera::ReadSVSCalib: Warning: Antiquated function: Use openCV calibration with ReadFromXML() instead of this function.\n");
  CDataFile file;
  if(file.Load(calibfile))
  {
    cam[LEFT].width = file.GetInt("pwidth", "left camera");
    cam[LEFT].height = file.GetInt("pheight", "left camera");
    cam[LEFT].fx = file.GetFloat("f", "left camera");
    cam[LEFT].fy = file.GetFloat("fy", "left camera");
    cam[LEFT].cx = file.GetFloat("Cx", "left camera");
    cam[LEFT].cy = file.GetFloat("Cy", "left camera");
    cam[LEFT].k1 = file.GetFloat("kappa1", "left camera");
    cam[LEFT].k2 = file.GetFloat("kappa2", "left camera");
    cam[LEFT].k3 = file.GetFloat("kappa3", "left camera");
    cam[LEFT].t1 = file.GetFloat("tau1", "left camera");
    cam[LEFT].t2 = file.GetFloat("tau2", "left camera");

    string str1 = file.GetString("proj", "left camera");
    istringstream sstr1(str1);
    ReadMat34(sstr1, cam[LEFT].proj);

    string str2 = file.GetString("rect", "left camera");
    istringstream sstr2(str2);
    ReadMat33(sstr2, cam[LEFT].rect);

    cam[RIGHT].width = file.GetInt("pwidth", "right camera");
    cam[RIGHT].height = file.GetInt("pheight", "right camera");
    cam[RIGHT].fx = file.GetFloat("f", "right camera");
    cam[RIGHT].fy = file.GetFloat("fy", "right camera");
    cam[RIGHT].cx = file.GetFloat("Cx", "right camera");
    cam[RIGHT].cy = file.GetFloat("Cy", "right camera");
    cam[RIGHT].k1 = file.GetFloat("kappa1", "right camera");
    cam[RIGHT].k2 = file.GetFloat("kappa2", "right camera");
    cam[RIGHT].k3 = file.GetFloat("kappa3", "right camera");
    cam[RIGHT].t1 = file.GetFloat("tau1", "right camera");
    cam[RIGHT].t2 = file.GetFloat("tau2", "right camera");

    string str3 = file.GetString("proj", "right camera");
    istringstream sstr3(str3);
    ReadMat34(sstr3, cam[RIGHT].proj);

    string str4 = file.GetString("rect", "right camera");
    istringstream sstr4(str4);
    ReadMat33(sstr4, cam[RIGHT].rect);


    // read poses
    // Note: an ideal camera is the camera associated with the ideal, i.e. rectified
    // image
    // We have:
    // - pose of the whole stereo rig, we call that the global rig pose
    //   (this->pose)
    // - pose of the left ideal camera relative to the rig (cam[LEFT]->pose), we assume
    //   this to be identity (as is quite common), so global rig pose and global
    //   ideal left camera pose are the same
    // - global pose of left ideal camera, same as global rig pose (see above).
    //   This is called "global" in the calibration file.
    // - pose of the right ideal camera relative to the rig (cam[RIGHT]->pose).
    //   This is stored implicitly in the right projection matrix Pr:
    //   relative right ideal pose is identity except x = -Pr(0,3)/Pr(0,0)
    //   (Note: What is called "external" in the calibration file (NOTE: Actually it is
    //   the inverse of "external"!) is the pose of the real (not ideal) right camera.)
    // - global pose of the right ideal camera, i.e. global rig pose + relative ideal
    //   right pose

    Vector3 r;
    pose.pos.x = file.GetFloat("GTx", "global");
    pose.pos.y = file.GetFloat("GTy", "global");
    pose.pos.z = file.GetFloat("GTz", "global");
    // SVS uses mm, we use m
    pose.pos /= 1000.;
    r.x = file.GetFloat("GRx", "global");
    r.y = file.GetFloat("GRy", "global");
    r.z = file.GetFloat("GRz", "global");
    fromRotVector(pose.rot, r);

    setIdentity(cam[LEFT].pose);

    setIdentity(cam[RIGHT].pose);
    cam[RIGHT].pose.pos.x = -cam[RIGHT].proj[0][3]/cam[RIGHT].proj[0][0];
    // SVS uses mm, we use m
    cam[RIGHT].pose.pos /= 1000.;

    /* Note: the following would get the real (not ideal) right camera pose
    cam[RIGHT].pose.pos.x = file.GetFloat("Tx", "external");
    cam[RIGHT].pose.pos.y = file.GetFloat("Ty", "external");
    cam[RIGHT].pose.pos.z = file.GetFloat("Tz", "external");
    // SVS use mm, we use m
    cam[RIGHT].pose.pos /= 1000.;
    r.x = file.GetFloat("Rx", "external");
    r.y = file.GetFloat("Ry", "external");
    r.z = file.GetFloat("Rz", "external");
    fromRotVector(cam[RIGHT].pose.rot, r);
    // "external" is the pose of the left w.r.t. right camera, so need to
    // invert:
    inverse(cam[RIGHT].pose, cam[RIGHT].pose);*/

    assert(cam[LEFT].width == cam[RIGHT].width);
    assert(cam[LEFT].height == cam[RIGHT].height);

    inImgSize.width = cam[LEFT].width;
    inImgSize.height = cam[LEFT].height;
    sx = 1.;
    sy = 1.;
  
  
    return true;
  } 
  else return false;
}

/**
 * @brief Point (X,Y,Z) is given in coor sys of left camera. Project to image plane
 * @param X 3D-coordinate x
 * @param Y 3D-coordinate y
 * @param Z 3D-coordinate z
 * @param u 2D-coordinate u in image plane
 * @param v 2D-coordinate v in image plane
 * @param side Left or right side of stereo rig.
 * @param imgWidth image width
 */
// void StereoCamera::ProjectPoint(double X, double Y, double Z,
//     double &u, double &v, int side)
// {
//   assert(Z != 0.);
//   // get from m to mm
//   X *= 1000.;
//   Y *= 1000.;
//   Z *= 1000.;
//   u = sx*cam[side].proj[0][0]*X + sx*cam[side].proj[0][2]*Z +
//       sx*cam[side].proj[0][3];
//   v = sy*cam[side].proj[1][1]*Y + sy*cam[side].proj[1][2]*Z;
//   // w = Z;
//   u /= Z;
//   v /= Z;
// }
void StereoCamera::ProjectPoint(double X, double Y, double Z, double &u, double &v, int side, int imgWidth)
{
  double scale = 1;
  assert(Z != 0.);
  if(imgWidth !=0) scale = cam[0].width / imgWidth;
  u = cam[side].proj[0][0]*X/scale + cam[side].proj[0][2]*Z/scale + cam[side].proj[0][3]/scale;
  v = cam[side].proj[1][1]*Y/scale + cam[side].proj[1][2]*Z/scale;
  // w = Z;
  u /= Z;
  v /= Z;
}


/**
 * Given a point in the left image and its disparity, return the reconstructed
 * 3D point.
 * @return true if disparity was valid and point could be resonstructed, false otherwise
 */
bool StereoCamera::ReconstructPoint(double u, double v, double d, double &X, double &Y, double &Z)
{
  // a disparity value of 0 or -1 (depending on which matching algorithm is used)
  // indicates invalid disparity
  if(d > (double)stereo_bm_state->minDisparity)
  {
    // NOTE: actually tx = -proj[0][3]/proj[0][0] because:
    // proj[0][3] = -fx*tx  (where fx = proj[0][0])
    // but there seems to be an error in the SVS calib file:
    //   [external]
    //   Tx = -202.797
    //   [right camera]
    //   proj = 640 ... -1.297899e+05  (this should be positive!)
    // This should be further investigated!!!
    double tx = cam[RIGHT].proj[0][3]/cam[RIGHT].proj[0][0];
    X = u - sx*cam[LEFT].proj[0][2];
    Y = v - sy*cam[LEFT].proj[1][2];
    Z = sx*cam[LEFT].proj[0][0];
    double W = -d/tx + sx*(cam[LEFT].proj[0][2] - cam[RIGHT].proj[0][2])/tx;
    // SVS calibration uses mm, we want m -> divide by 1000
    W *= 1000.;
    X /= W;
    Y /= W;
    Z /= W;
    return true;
  }
  else
  {
    return false;
  }
}

void StereoCamera::DistortNormalisedPoint(double x, double y,
    double &xd, double &yd, int side)
{
  double x2 = x*x;
  double y2 = y*y;
  double r2 = x2 + y2;
  double r4 = r2*r2;
  double r6 = r4*r2;
  double t = (1. + cam[side].k1*r2 + cam[side].k2*r4 + cam[side].k3*r6);
  xd = x*t + 2.*cam[side].t1*x*y + cam[side].t2*(r2 + 2.*x2);
  yd = y*t + 2.*cam[side].t2*x*y + cam[side].t1*(r2 + 2.*y2);
}

void StereoCamera::DistortPoint(double u, double v, double &ud, double &vd, int side)
{
  double x = (u - sx*cam[side].cx)/(sx*cam[side].fx);
  double y = (v - sy*cam[side].cy)/(sy*cam[side].fy);
  double xd, yd;
  DistortNormalisedPoint(x, y, xd, yd, side);
  ud = xd*sx*cam[side].fx + sx*cam[side].cx;
  vd = yd*sy*cam[side].fy + sy*cam[side].cy;
}

/**
 * gradient based method for undistortion
 */
bool StereoCamera::UndistortPoint(double ud, double vd, double &u, double &v, int side)
{
  const unsigned MAX_ITER = 100;
  double error = DBL_MAX;
  double gradx = 0, grady = 0;
  double currentx, currenty;
  unsigned z;
  u = ud;
  v = vd;

  for(z = 0; z < MAX_ITER && error > maxDistortion; z++)
  {
    u += gradx;
    v += grady;
    DistortPoint(u, v, currentx, currenty, side);
    gradx = ud - currentx;
    grady = vd - currenty;
    error = gradx*gradx + grady*grady;
  }
  if(u < 0)
    u = 0;
  if(u >= inImgSize.width)
    u = inImgSize.width - 1;
  if(v < 0)
    v = 0;
  if(v >= inImgSize.height)
    v = inImgSize.height - 1;
  if(z < MAX_ITER)
    return true;
  return false;
}

void StereoCamera::RectifyPoint(double ud, double vd, double &ur, double &vr, int side)
{
  double u, v;
  UndistortPoint(ud, vd, u, v, side);
  double x = (u - sx*cam[side].cx)/(sx*cam[side].fx);
  double y = (v - sy*cam[side].cy)/(sy*cam[side].fy);
  double xr = cam[side].rect[0][0]*x + cam[side].rect[0][1]*y +
    cam[side].rect[0][2];
  double yr = cam[side].rect[1][0]*x + cam[side].rect[1][1]*y +
    cam[side].rect[1][2];
  double wr = cam[side].rect[2][0]*x + cam[side].rect[2][1]*y +
    cam[side].rect[2][2];
  xr /= wr;
  yr /= wr;
  ur = xr*sx*cam[side].proj[0][0] + sx*cam[side].proj[0][2];
  vr = yr*sy*cam[side].proj[1][1] + sy*cam[side].proj[1][2];
}

void StereoCamera::UnrectifyPointFast(double ur, double vr, double &ud, double &vd,
    int side)
{
  int ui = (int)floor(ur), vi =  (int)floor(vr);
  if(ui >= 0 && ui < inImgSize.width && vi >= 0 && vi < inImgSize.height)
  {
    ud = *(float*)cvAccessImageData(mapx[side], ui, vi);
    vd = *(float*)cvAccessImageData(mapy[side], ui, vi);
  }
  else
  {
    ud = vd = 0.;
  }
}

void StereoCamera::SetupImageRectification()
{
  for(int side = LEFT; side <= RIGHT; side++)
  {
    CvMat R = cvMat(3, 3, CV_64FC1, cam[side].rect);
    // inverse of rectification matrix: xu = R_i * xi (with xu and xi
    // homogeneous)
    double r_i[3][3];
    CvMat R_i = cvMat(3, 3, CV_64FC1, r_i);
    cvInvert(&R, &R_i);
    // make sure this function is only called once
    assert(mapx[side] == 0);
    mapx[side] = cvCreateImage(inImgSize, IPL_DEPTH_32F, 1);
    mapy[side] = cvCreateImage(inImgSize, IPL_DEPTH_32F, 1);
    //cvSetZero(mapx[side]);
    //cvSetZero(mapy[side]);
    // iterate over ideal image coords
    for(int vi = 0; vi < inImgSize.height; vi++)
    {
      for(int ui = 0; ui < inImgSize.width; ui++)
      {
        // ideal normalised coords
        double xi = (ui - sx*cam[side].proj[0][2])/(sx*cam[side].proj[0][0]);
        double yi = (vi - sy*cam[side].proj[1][2])/(sy*cam[side].proj[1][1]);
        // undistorted normalised coords
        double xu = r_i[0][0]*xi + r_i[0][1]*yi + r_i[0][2];
        double yu = r_i[1][0]*xi + r_i[1][1]*yi + r_i[1][2];
        double wu = r_i[2][0]*xi + r_i[2][1]*yi + r_i[2][2];
        assert(!iszero(wu));
        xu /= wu;
        yu /= wu;
        // distorted normalised coords
        double xd, yd;
        DistortNormalisedPoint(xu, yu, xd, yd, side);
        // distorted image coords
        double ud = xd*sx*cam[side].fx + sx*cam[side].cx;
        double vd = yd*sy*cam[side].fy + sy*cam[side].cy;
        *(float*)cvAccessImageData(mapx[side], ui, vi) = ud;
        *(float*)cvAccessImageData(mapy[side], ui, vi) = vd;
      }
    }
    //cvDeleteMoire(mapx[side]);
    //cvDeleteMoire(mapy[side]);
  }
}

void StereoCamera::RectifyImage(const IplImage *src, IplImage *dst, int side)
{
  assert(src != 0 && dst != 0);
  cvRemap(src, dst, mapx[side], mapy[side],
          CV_INTER_LINEAR + CV_WARP_FILL_OUTLIERS, cvScalarAll(0));
}

void StereoCamera::CalculateDisparity(const IplImage *left, const IplImage *right,
      IplImage *disp)
{
  assert(left != 0 && right != 0 && disp != 0);
  if(matchAlgorithm == BLOCK_MATCH)
  {
    //cvFindStereoCorrespondenceBM(left, right, disp, stereo_bm_state);
    stereoBM->init(cv::StereoBM::BASIC_PRESET, stereo_bm_state->numberOfDisparities);
    cv::Mat leftM(left, false);
    cv::Mat rightM(right, false);
    cv::Mat dispM(disp, false);
    (*stereoBM)(leftM, rightM, dispM, CV_32F);
  }
  else if(matchAlgorithm == SEMI_GLOBAL_BLOCK_MATCH)
  {
    // it is safe to directly access the settings values of cv::StereoSGBM
    stereoSGBM->numberOfDisparities = stereo_bm_state->numberOfDisparities;
    cv::Mat leftM(left, false);
    cv::Mat rightM(right, false);
    cv::Mat dispM(disp, false);
    cv::Mat dispM_short(dispM.rows, dispM.cols, CV_16S);
    (*stereoSGBM)(leftM, rightM, dispM_short);
    dispM_short.convertTo(dispM, CV_32F, 1./(double)stereoSGBM->DISP_SCALE);
  }
  else
    assert("only supports BLOCK_MATCH for now" == 0);
}

void StereoCamera::SetInputImageSize(CvSize size)
{
  inImgSize = size;
  // NOTE: I assume that of course left and right camera have the same
  // width/height
  sx = (double)inImgSize.width/(double)cam[LEFT].width;
  sy = (double)inImgSize.height/(double)cam[LEFT].height;
}

void StereoCamera::SetDisparityRange(int minDisp, int maxDisp)
{
  // note: disparity limits must by divisible by 16 - q requirement by
  // OpenCV stereo matching
  minDisp = minDisp - minDisp%16;
  maxDisp = maxDisp - maxDisp%16;
  stereo_bm_state->minDisparity = minDisp;
  stereo_bm_state->numberOfDisparities = maxDisp - minDisp;
}

void StereoCamera::SetMatchingAlgoritm(MatchingAlgorithm algo)
{
  matchAlgorithm = algo;
}

cv::Mat StereoCamera::GetIntrinsic(unsigned side)
{
  cv::Mat mat = (cv::Mat_<double>(3,3) << cam[side].fx,0,cam[side].cx, 0,cam[side].fy,cam[side].cy, 0,0,1);
  return mat;
}
}

