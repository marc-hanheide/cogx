This project recognizes the objects in the scene object and estimate their pose.
Once the pose has been estimated, the overlap between the CAD model and the
pointcloud from the kinect is computed. It generates an IV and VTK file that
are used by OpenRave later on.

Depends on the following projects:
 * generic_trainer_recognizer 
 
To start the code after compilation:

    ./test_overlap [path_to_scaled_CAD_models] [path_where_to_store_CVFH_descriptors] [path_where_to_store_IV_and_VTK] [scale_factor (use always 1)] [scene (optional)]

    Example with a scene:
    ./test_overlap /home/aitor/data/CAD-net/learned_scaled_models /home/aitor/data/CAD-net/learned_scaled_models_trained_cvfh /home/aitor/models_overlap_likelihood 1 /home/aitor/data/CAD-net/points2/chair_1.pcd 

    With the Kinect plugged in, the last scene parameter can be skipped and the scene obtained directly from the Kinect:
    ./test_overlap /home/aitor/data/CAD-net/learned_scaled_models /home/aitor/data/CAD-net/learned_scaled_models_trained_cvfh /home/aitor/models_overlap_likelihood 1

    The pointcloud from the Kinect is visualized until the user closes the window and then the learning starts. 
    Once an object has been learned, the visualization of the kinect pointcloud starts again.

Things that are visualized:

 * aligned CAD models with the scene, color represent the distance from CAD model to the pointcloud

TODO:
 * the generated IV and VTK files should be sent to OpenRave so that the grasping can start.